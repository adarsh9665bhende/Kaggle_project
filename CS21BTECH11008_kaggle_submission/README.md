##### CS3390 - Foundations of Machine Learning

# Kaggle Competition

### Team Members

- **CS21BTECH11008** Adarsh Suresh Bhende
- **CS21BTECH11026** K Vivek Kumar

### Requirements

**Python Libraries:** Numpy, Pandas, Seaborn, Matplotlib, sklearn

You can download them using:

```
pip install numpy pandas seaborn matplotlib sklearn
```

### Running the Code

Follow the below steps for running the submitted files

- Download the submitted zip folder, `CS21BTECH11008_kaggle.zip` and extract it to an existing directory.

- Navigate to that directory

```
cd CS21BTECH11008_kaggle
```

- Ensure the following files are present in that directory.

  - `gradient_boost.ipynb`
  - `randomforest.ipynb`
  - `train_input.csv`
  - `test_input.csv`

- Each code is written in each of the jupyter notebook files. You can run each of the notebooks by opening it.

- Open the notebook and click on `Run All Cells`

- **Note:** Running `gradient_boost.ipynb` will generate the `test_output1.csv` and `randomforest.ipynb` would generate the `test_output2.csv` as their output files.

- You can run the accuracy test on the `test_output1.csv` and `test_output2.csv` files.

### Obtained Accuracy

On submitting these files on the kaggle hackathon page, we obtained the following accuracy results:

- `gradient_boost.ipynb`
  - `test_output1.csv`: **Accuracy** =
- `randomforest.ipynb`
  - `test_output2.csv`: **Accuracy** =
